<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Publications - Shadman Sobhan</title>
  <!-- External Styles (Match index.html) -->
  <link href="https://cdn.replit.com/agent/bootstrap-agent-dark-theme.min.css" rel="stylesheet">
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">
  <link href="./style.css" rel="stylesheet">
</head>
<body>
  <!-- Navigation -->
  <nav class="navbar navbar-expand-lg navbar-dark bg-dark fixed-top">
    <div class="container">
      <a class="navbar-brand fw-bold" href="index.html">
        <i class="fas fa-user-graduate me-2"></i>Shadman Sobhan
      </a>
      <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav">
        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse" id="navbarNav">
        <ul class="navbar-nav ms-auto">
          <li class="nav-item">
            <a class="nav-link" href="index.html">
              <i class="fas fa-home me-1"></i>Home
            </a>
          </li>
          <li class="nav-item">
            <a class="nav-link active" href="publications.html">
              <i class="fas fa-newspaper me-1"></i>Publications
            </a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="projects.html">
              <i class="fas fa-code me-1"></i>Projects
            </a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="experience.html">
              <i class="fas fa-briefcase me-1"></i>Experience
            </a>
          </li>
        </ul>
      </div>
    </div>
  </nav>

  <!-- Main Content -->
  <div class="container pt-5 mt-5">
    <!-- Header -->
    <div class="row mb-5">
      <div class="col-12 text-center">
        <h1 class="display-5 fw-bold mb-3">Research Publications</h1>
        <p class="lead text-secondary">
          Peer-reviewed publications, preprints, and manuscripts under review showcasing research expertise in AI, medical imaging, and computer vision.
        </p>
      </div>
    </div>

    <!-- Published Papers Section -->
    <div class="row mb-5">
      <div class="col-12">
        <h2 class="mb-4">
          <i class="fas fa-medal text-success me-3"></i>Published & Accepted Papers
        </h2>

        <!-- Publication Item 1 -->
        <div class="card mb-4 border-0 shadow-sm">
          <div class="card-body">
            <div class="row">
              <div class="col-md-10">
                <h5 class="card-title mb-2">A Multi-Stage Deep Learning Approach to Tuberculosis Detection with Explainable Insights</h5>
                <p class="card-text text-primary mb-2">
                  <strong>Authors:</strong> Shadman Sobhan et al.
                </p>
                <p class="card-text text-secondary mb-2">
                  <strong>Conference:</strong> NCIM 2025 (Dhaka)
                </p>
                <p class="card-text">
                  A comprehensive deep learning framework for tuberculosis detection using multi-stage 
                  approach with explainable AI insights to improve diagnostic accuracy and clinical interpretability.
                </p>
                <div class="d-flex flex-wrap gap-2 mt-3">
                  <span class="badge bg-success">Accepted</span>
                  <span class="badge bg-secondary">Medical Imaging</span>
                  <span class="badge bg-secondary">Deep Learning</span>
                  <span class="badge bg-secondary">XAI</span>
                </div>
              </div>
              <div class="col-md-2 text-md-end mt-3 mt-md-0">
                <div class="mb-2">
                  <span class="badge bg-primary fs-6">2025</span>
                </div>
                <div class="d-flex flex-column gap-2">
                  <span class="btn btn-sm btn-outline-primary disabled">
                    <i class="fas fa-clock me-1"></i>In Press
                  </span>
                </div>
              </div>
            </div>
          </div>
        </div>

        <!-- Publication Item 2 -->
        <div class="card mb-4 border-0 shadow-sm">
          <div class="card-body">
            <div class="row">
              <div class="col-md-10">
                <h5 class="card-title mb-2">Skin Cancer Classification Using Pre-trained CNNs: A Transfer Learning Approach Addressing Imbalanced Data Challenges</h5>
                <p class="card-text text-primary mb-2">
                  <strong>Authors:</strong> Shadman Sobhan et al.
                </p>
                <p class="card-text text-secondary mb-2">
                  <strong>Conference:</strong> NCIM 2025 (Dhaka)
                </p>
                <p class="card-text">
                  A transfer learning approach using pre-trained CNNs to address imbalanced data challenges 
                  in skin cancer classification, improving diagnostic accuracy for dermatological applications.
                </p>
                <div class="d-flex flex-wrap gap-2 mt-3">
                  <span class="badge bg-success">Accepted</span>
                  <span class="badge bg-secondary">Computer Vision</span>
                  <span class="badge bg-secondary">Transfer Learning</span>
                  <span class="badge bg-secondary">Medical AI</span>
                </div>
              </div>
              <div class="col-md-2 text-md-end mt-3 mt-md-0">
                <div class="mb-2">
                  <span class="badge bg-primary fs-6">2025</span>
                </div>
                <div class="d-flex flex-column gap-2">
                  <span class="btn btn-sm btn-outline-primary disabled">
                    <i class="fas fa-clock me-1"></i>In Press
                  </span>
                </div>
              </div>
            </div>
          </div>
        </div>

        <!-- Publication Item 3 -->
        <div class="card mb-4 border-0 shadow-sm">
          <div class="card-body">
            <div class="row">
              <div class="col-md-10">
                <h5 class="card-title mb-2">A Lightweight Framework for Facial Emotion Recognition: Leveraging Geometrical Priors with Spatial Features</h5>
                <p class="card-text text-primary mb-2">
                  <strong>Authors:</strong> Abduz Zami, Shadman Sobhan et al.
                </p>
                <p class="card-text text-secondary mb-2">
                  <strong>Conference:</strong> NCIM 2025 (Dhaka)
                </p>
                <p class="card-text">
                  A lightweight framework combining geometrical priors with spatial features for efficient 
                  facial emotion recognition with reduced computational complexity.
                </p>
                <div class="d-flex flex-wrap gap-2 mt-3">
                  <span class="badge bg-success">Accepted</span>
                  <span class="badge bg-secondary">Computer Vision</span>
                  <span class="badge bg-secondary">Emotion Recognition</span>
                  <span class="badge bg-secondary">Lightweight Model</span>
                </div>
              </div>
              <div class="col-md-2 text-md-end mt-3 mt-md-0">
                <div class="mb-2">
                  <span class="badge bg-primary fs-6">2025</span>
                </div>
                <div class="d-flex flex-column gap-2">
                  <span class="btn btn-sm btn-outline-primary disabled">
                    <i class="fas fa-clock me-1"></i>In Press
                  </span>
                </div>
              </div>
            </div>
          </div>
        </div>

        <!-- Publication Item 4 -->
        <div class="card mb-4 border-0 shadow-sm">
          <div class="card-body">
            <div class="row">
              <div class="col-md-10">
                <h5 class="card-title mb-2">TIG-UNet++: A Thresholded Input Guided Modified UNet++ for Separating Lung Region in Chest X-Rays</h5>
                <p class="card-text text-primary mb-2">
                  <strong>Authors:</strong> Abduz Zami, Shadman Sobhan et al.
                </p>
                <p class="card-text text-secondary mb-2">
                  <strong>Conference:</strong> ICTIS 2025 (Bangkok, Thailand)
                </p>
                <p class="card-text">
                  A modified UNet++ architecture with thresholded input guidance for improved lung region 
                  segmentation in chest X-rays, enhancing medical image analysis capabilities.
                </p>
                <div class="d-flex flex-wrap gap-2 mt-3">
                  <span class="badge bg-success">Accepted</span>
                  <span class="badge bg-secondary">Medical Imaging</span>
                  <span class="badge bg-secondary">Segmentation</span>
                  <span class="badge bg-secondary">UNet++</span>
                </div>
              </div>
              <div class="col-md-2 text-md-end mt-3 mt-md-0">
                <div class="mb-2">
                  <span class="badge bg-primary fs-6">2025</span>
                </div>
                <div class="d-flex flex-column gap-2">
                  <span class="btn btn-sm btn-outline-primary disabled">
                    <i class="fas fa-clock me-1"></i>In Press
                  </span>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>

    <!-- Preprints & Under Review Section -->
    <div class="row">
      <div class="col-12">
        <div class="alert alert-info mb-4" role="alert">
          <h4 class="alert-heading"><i class="fas fa-file-alt me-2"></i>Preprints & Under Review</h4>
          <p class="mb-0">Research works available as preprints or currently under peer review at various venues.</p>
        </div>

        <!-- Preprint 1 -->
        <div class="card mb-4 border-0 shadow-sm bg-body-secondary">
          <div class="card-body">
            <div class="row">
              <div class="col-md-10">
                <h5 class="card-title mb-2">LLM-Assisted Question-Answering on Technical Documents Using Structured Data-Aware Retrieval Augmented Generation</h5>
                <p class="card-text text-primary mb-2">
                  <strong>Authors:</strong> Shadman Sobhan (Undergraduate Thesis)
                </p>
                <p class="card-text text-secondary mb-2">
                  <strong>Supervisor:</strong> Dr. Mohammad Ariful Haque
                </p>
                <p class="card-text">
                  In this work, we propose a RAG pipeline, capable of handling tables and images in documents, for technical documents that support both scanned and searchable formats.
                </p>
                <div class="d-flex flex-wrap gap-2 mt-3">
                  <span class="badge bg-warning text-dark">Preprint</span>
                  <span class="badge bg-secondary">NLP</span>
                  <span class="badge bg-secondary">RAG</span>
                  <span class="badge bg-secondary">LLM</span>
                </div>
              </div>
              <div class="col-md-2 text-md-end mt-3 mt-md-0">
                <div class="mb-2">
                  <span class="badge bg-warning fs-6">arXiv</span>
                </div>
                <div class="d-flex flex-column gap-2">
                  <a href="https://arxiv.org/abs/2506.23136" class="btn btn-sm btn-outline-warning" target="_blank">
                    <i class="fas fa-external-link-alt me-1"></i>arXiv
                  </a>
                </div>
              </div>
            </div>
          </div>
        </div>

        <!-- Preprint 2 -->
        <div class="card mb-4 border-0 shadow-sm bg-body-secondary">
          <div class="card-body">
            <div class="row">
              <div class="col-md-10">
                <h5 class="card-title mb-2">MedPrompt: LLM-CNN Fusion with Weight Routing for Medical Image Segmentation and Classification</h5>
                <p class="card-text text-primary mb-2">
                  <strong>Authors:</strong> Shadman Sobhan et al.
                </p>
                <p class="card-text text-secondary mb-2">
                  <strong>Status:</strong> Preprint available at arXiv
                </p>
                <p class="card-text">
                  We introduced MedPrompt, a unified framework that combines a few-shot prompted Large Language Model 
                  for high-level task planning with a modular Convolutional Neural Network (DeepFusionLab) for low-level 
                  image processing.
                </p>
                <div class="d-flex flex-wrap gap-2 mt-3">
                  <span class="badge bg-warning text-dark">Preprint</span>
                  <span class="badge bg-secondary">Medical Imaging</span>
                  <span class="badge bg-secondary">LLM-CNN Fusion</span>
                  <span class="badge bg-secondary">Weight Routing</span>
                </div>
              </div>
              <div class="col-md-2 text-md-end mt-3 mt-md-0">
                <div class="mb-2">
                  <span class="badge bg-warning fs-6">arXiv</span>
                </div>
                <div class="d-flex flex-column gap-2">
                  <a href="https://arxiv.org/abs/2506.21199" class="btn btn-sm btn-outline-warning" target="_blank">
                    <i class="fas fa-external-link-alt me-1"></i>arXiv
                  </a>
                </div>
              </div>
            </div>
          </div>
        </div>

        <!-- Preprint 3 -->
        <div class="card mb-4 border-0 shadow-sm bg-body-secondary">
          <div class="card-body">
            <div class="row">
              <div class="col-md-10">
                <h5 class="card-title mb-2">Prompt2SegCXR: Prompt to Segment All Organs and Diseases in Chest X-rays</h5>
                <p class="card-text text-primary mb-2">
                  <strong>Authors:</strong> Abduz Zami, Shadman Sobhan et al.
                </p>
                <p class="card-text text-secondary mb-2">
                  <strong>Status:</strong> Preprint available at arXiv | Dataset on Mendeley
                </p>
                <p class="card-text">
                  This work introduces (1) a collection of expert-generated doodle prompts across 23 classes 
                  (6 organs and 17 diseases) from diverse datasets for prompt-based Chest X-ray segmentation, 
                  and (2) Prompt2SegCXR, a lightweight model for accurate multi-class organ and disease segmentation
                  in Chest X-rays.
                </p>
                <div class="d-flex flex-wrap gap-2 mt-3">
                  <span class="badge bg-warning text-dark">Preprint</span>
                  <span class="badge bg-secondary">Medical Imaging</span>
                  <span class="badge bg-secondary">Prompt Engineering</span>
                  <span class="badge bg-secondary">Dataset</span>
                </div>
              </div>
              <div class="col-md-2 text-md-end mt-3 mt-md-0">
                <div class="mb-2">
                  <span class="badge bg-warning fs-6">arXiv</span>
                </div>
                <div class="d-flex flex-column gap-2">
                  <a href="https://arxiv.org/abs/2507.00673" class="btn btn-sm btn-outline-warning" target="_blank">
                    <i class="fas fa-external-link-alt me-1"></i>arXiv
                  </a>
                  <a href="https://data.mendeley.com/datasets/mk36vt2nzj/1" class="btn btn-sm btn-outline-info" target="_blank">
                    <i class="fas fa-database me-1"></i>Dataset
                  </a>
                </div>
              </div>
            </div>
          </div>
        </div>

        <!-- Under Review 1 -->
        <div class="card mb-4 border-0 shadow-sm">
          <div class="card-body">
            <div class="row">
              <div class="col-md-10">
                <h5 class="card-title mb-2">DeepColonLab: Attention Guided Separable Receptive Field Block Enhanced Deeplabv3+ Model for Colon Polyp Segmentation</h5>
                <p class="card-text text-primary mb-2">
                  <strong>Authors:</strong> Abduz Zami, Shadman Sobhan et al.
                </p>
                <p class="card-text text-secondary mb-2">
                  <strong>Status:</strong> Under Review | Preprint available at preprints.org
                </p>
                <p class="card-text">
                  We introduced DeepColonLab, a modification of the DeepLabV3+ model, specially designed for colon polyp segmentation.
                </p>
                <div class="d-flex flex-wrap gap-2 mt-3">
                  <span class="badge bg-info">Under Review</span>
                  <span class="badge bg-secondary">Medical Imaging</span>
                  <span class="badge bg-secondary">Attention Mechanism</span>
                  <span class="badge bg-secondary">DeepLab</span>
                </div>
              </div>
              <div class="col-md-2 text-md-end mt-3 mt-md-0">
                <div class="mb-2">
                  <span class="badge bg-info fs-6">Review</span>
                </div>
                <div class="d-flex flex-column gap-2">
                  <a href="https://www.preprints.org/manuscript/202506.0380/v1" class="btn btn-sm btn-outline-info" target="_blank">
                    <i class="fas fa-external-link-alt me-1"></i>Preprint
                  </a>
                </div>
              </div>
            </div>
          </div>
        </div>

        <!-- Under Review 2 -->
        <div class="card mb-4 border-0 shadow-sm">
          <div class="card-body">
            <div class="row">
              <div class="col-md-10">
                <h5 class="card-title mb-2">UltraLightCPS: An Ultra-Lightweight Colon Polyp Segmentation Model using Adaptive Compressed Multi-Scale Semantic Fusion Mechanism</h5>
                <p class="card-text text-primary mb-2">
                  <strong>Authors:</strong> Abduz Zami, Shadman Sobhan et al.
                </p>
                <p class="card-text text-secondary mb-2">
                  <strong>Status:</strong> Under Review
                </p>
                <p class="card-text">
                  This research introduces UltraLightCPS, a novel colon polyp segmentation model designed to achieve 
                  high segmentation accuracy with extreme computational efficiency with only 0.23M parameters.
                </p>
                <div class="d-flex flex-wrap gap-2 mt-3">
                  <span class="badge bg-info">Under Review</span>
                  <span class="badge bg-secondary">Medical Imaging</span>
                  <span class="badge bg-secondary">Lightweight Model</span>
                  <span class="badge bg-secondary">Semantic Fusion</span>
                </div>
              </div>
              <div class="col-md-2 text-md-end mt-3 mt-md-0">
                <div class="mb-2">
                  <span class="badge bg-info fs-6">Review</span>
                </div>
                <div class="d-flex flex-column gap-2">
                  <span class="btn btn-sm btn-outline-secondary disabled">
                    <i class="fas fa-clock me-1"></i>Pending
                  </span>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>

  <!-- Footer -->
  <footer class="bg-dark text-light py-4">
    <div class="container">
      <div class="row">
        <div class="col-md-6">
          <p class="mb-0">&copy; 2025 Shadman Sobhan. All rights reserved.</p>
        </div>
        <div class="col-md-6 text-md-end">
          <p class="mb-0">Built with passion for AI and innovation</p>
        </div>
      </div>
    </div>
  </footer>

  <!-- Scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
  <script src="./main.js"></script>
</body>
</html>
